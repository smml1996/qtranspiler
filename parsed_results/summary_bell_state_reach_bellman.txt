------ Experiment.bell_state_reach ------
%%%%%%%%%%%% bellman %%%%%%%%%%%%
count hardware (bellman):  45
count embeddings (bellman):  3317
total diff. algorithms (bellman):  9
accuracy perfect hardware (bellman): 0.6, 1.0, 1.0

min. accuracy (bellman): 0.28
avg. accuracy (bellman): 0.77402
max. accuracy (bellman): 1.0

min. pomdp build time (bellman): 0.01172
avg. pomdp build time (bellman): 1.14958
max. pomdp build time (bellman): 3.48319

min. method time (bellman): 0.0
avg. method time (bellman): 6e-05
max. method time (bellman): 0.5972

min. total time (bellman): 0.01172
avg. total time (bellman): 1.14958
max. total time (bellman): 3.48319

min. total time (bellman): 0.01172
avg. total time (bellman): 1.14958
max. total time (bellman): 3.48319

num. algorithms per horizon (method=bellman)
1 :  1
2 :  3
3 :  5
--


number of improvements per horizon:
--> horizon 1: 0 
--> horizon 2: 268 
--> horizon 3: 3316 


Improvements with respect to perfect algorithms per horizon
Horizon = 1

Horizon = 2
-> Algorithm: 11
--> Max: (0.06345, ('lagos', 9))
--> Avg: -0.283197386192342
--> Std: 0.13502388390436526
-> Algorithm: 7
--> Max: (0.02172999999999997, ('manhattan', 14))
--> Avg: -0.5627823334338217
--> Std: 0.16489213129610308

Horizon = 3
-> Algorithm: 12
--> Max: (0.11292000000000002, ('lagos', 9))
--> Avg: -0.26824574314139327
--> Std: 0.15050256369810583
-> Algorithm: 4
--> Max: (0.09892999999999996, ('lagos', 9))
--> Avg: 0.029903436840518185
--> Std: 0.033021992322787394
-> Algorithm: 8
--> Max: (0.05686000000000002, ('manhattan', 14))
--> Avg: -0.2203544950256256
--> Std: 0.08938502768883279
-> Algorithm: 17
--> Max: (0.049470000000000014, ('lagos', 9))
--> Avg: 0.014951643050949431
--> Std: 0.016511019410864327
-> Algorithm: 5
--> Max: (0.04298000000000002, ('washington', 38))
--> Avg: -0.40214495628579994
--> Std: 0.12259920293176879



